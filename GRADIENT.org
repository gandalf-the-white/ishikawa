#+title: Gradient

* Gradient descent
This involves adjusting the parameters \textbf{W} and \textbf{b} in order to minimize model errors, i.e., to minimize the \textbf{cost function} (Log Loss).\\
That is why we calculate the gradient (or derivative) of the \textbf{cost function}.
** Gradient descent algorithm
#+begin_src latex
\begin{align*}
    W &= W - \alpha \times \frac{\partial \mathcal{L}}{\delta W}\\
    b &= b - \alpha \times \frac{\delta \mathcal{L}}{\delta b}
\end{align*}
#+end_src
** Decomposition
#+begin_src latex
\begin{equation*}
    \frac{\delta{\mathcal{L}}}{\delta w_1} = \frac{\delta\mathcal{L}}{\delta a}\times\frac{\delta a}{\delta z}\times\frac{\delta z}{\delta w_1}
\end{equation*}
#+end_src
** Calculation of $\frac{\delta \mathcal{L}}{\delta a}$
#+begin_src latex
\begin{align*}
    \frac{\delta \mathcal{L}}{\delta a} &= -\frac{1}{m}\sum_{i=1}^m(\frac{y_i}{a_i}-\frac{1-y_i}{1-a_i})\\
    &= -\frac{1}{m}\sum_{i=1}^m(\frac{y_i-a_iy_i-a_i+a_iy_i}{a_i(1-a_i)})\\
    &= -\frac{1}{m}\sum_{i=1}^m(\frac{y_i-a_i}{a_i(1-a_i)})
\end{align*}
#+end_src
** Calculation of $\frac{\delta a}{\delta z}$
Let us choose $h=g \circ f$ with $f(z) = 1+e^{-z}$ and $g(f(z))=\frac{1}{f(z)}$, i.e.
#+begin_src latex
\begin{align*}
    h' &= g'(f(z))f'(z)\\
       &= -\frac{1}{f(z)^2}\times (-e^{-z})\\
       &= \frac{e^{-z}}{(1+e^{-z})^2}\\
       &= \frac{1-1+e^{-z}}{(1+e^{-z})^2}\\
       &= -\frac{1}{(1+e^{-z})^2}+\frac{1+e^{-z}}{(1+e^{-z})^2}\\
       &= \frac{1}{1+e^{-z}}-\frac{1}{(1+e^{-z})^2}\\
       &= (\frac{1}{1+e^{-z}})(1-\frac{1}{1+e^{-z}})
\end{align*}
#+end_src
In conclusion, we obtain
#+begin_src latex
\begin{equation*}
    \frac{\delta a}{\delta z} = a(z)(1-a(z))
\end{equation*}
#+end_src
** Calculation of $\frac{\delta z}{\delta w_1}$
#+begin_src latex
\begin{align*}
    z &= w_1x_1+w_2x_2+b\\
    \frac{\delta z}{\delta w_1} &= x_1
\end{align*}
#+end_src
** Calculation of $\frac{\delta z}{\delta w_2}$
#+begin_src latex
\begin{align*}
    z &= w_1x_1+w_2x_2+b\\
    \frac{\delta z}{\delta w_2} &= x_2
\end{align*}
#+end_src
** Calculation of $\frac{\delta z}{\delta b}$
#+begin_src latex
\begin{align*}
    z &= w_1x_1+w_2x_2+b\\
    \frac{\delta z}{\delta b} &= 1
\end{align*}
#+end_src
** Conclusion for $\frac{\delta \mathcal{L}}{\delta w_1}$
#+begin_src latex
\begin{align*}
    \frac{\delta \mathcal{L}}{\delta w_1} &= \frac{\delta\mathcal{L}}{\delta a}\times\frac{\delta a}{\delta z}\times\frac{\delta z}{\delta w_1}\\
    &= (-\frac{1}{m}\sum_{i=1}^m(\frac{y_i-a_i}{a_i(1-a_i)}))(a(z)(1-a(z)))(x_1)\\
    &= -\frac{1}{m}\sum_{i=1}^m(y_i-a_i)x_1
\end{align*}
#+end_src
** Conclusion for $\frac{\delta \mathcal{L}}{\delta w_2}$
#+begin_src latex
\begin{align*}
    \frac{\delta \mathcal{L}}{\delta w_2} &= \frac{\delta\mathcal{L}}{\delta a}\times\frac{\delta a}{\delta z}\times\frac{\delta z}{\delta w_2}\\
    &= (-\frac{1}{m}\sum_{i=1}^m(\frac{y_i-a_i}{a_i(1-a_i)}))(a(z)(1-a(z)))(x_2)\\
    &= -\frac{1}{m}\sum_{i=1}^m(y_i-a_i)x_2
\end{align*}
#+end_src
** Conclusion for $\frac{\delta \mathcal{L}}{\delta b}$
#+begin_src latex
\begin{align*}
    \frac{\delta \mathcal{L}}{\delta b} &= \frac{\delta\mathcal{L}}{\delta a}\times\frac{\delta a}{\delta z}\times\frac{\delta z}{\delta b}\\
    &= (-\frac{1}{m}\sum_{i=1}^m(\frac{y_i-a_i}{a_i(1-a_i)}))(a(z)(1-a(z)))\\
    &= -\frac{1}{m}\sum_{i=1}^m(y_i-a_i)
\end{align*}
#+end_src
** Conclusion
For our gradient descent
#+begin_src latex
\begin{align*}
    W &= W - \alpha \frac{\partial \mathcal{L}}{\delta W}\\
    b &= b - \alpha \frac{\delta \mathcal{L}}{\delta b}
\end{align*}
#+end_src
we obtain the following gradients:
#+begin_src latex
\begin{align*}
    \frac{\delta \mathcal{L}}{\delta w_1} &= -\frac{1}{m}\sum_{i=1}^m(y_i-a_i)x_1\\
    \frac{\delta \mathcal{L}}{\delta w_2} &= -\frac{1}{m}\sum_{i=1}^m(y_i-a_i)x_2\\
    \frac{\delta \mathcal{L}}{\delta b} &= -\frac{1}{m}\sum_{i=1}^m(y_i-a_i)
\end{align*}
#+end_src
That mean:
#+begin_src latex
\begin{align*}
    w_1 &= w_1 - \alpha \times \frac{1}{m}\sum_{i=1}^m(y_i-a_i)x_1\\
    w_2 &= w_2 - \alpha \times \frac{1}{m}\sum_{i=1}^m(y_i-a_i)x_2\\
    b &= b - \alpha \times \frac{1}{m}\sum_{i=1}^m(y_i-a_i)
\end{align*}
#+end_src
